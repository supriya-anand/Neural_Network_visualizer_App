{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalize data\n",
    "# uncomment next two lines to findout the shape of train and test set\n",
    "# x_train.shape  \n",
    "# x_test.shape\n",
    "\n",
    "x_train = np.reshape(x_train, (60000, 28*28))\n",
    "x_test = np.reshape(x_test, (10000, 28*28))\n",
    "#Normalization\n",
    "x_train = x_train/255.\n",
    "x_test = x_test/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Neural Network\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(32, activation = 'sigmoid', input_shape=(784,)),\n",
    "    tf.keras.layers.Dense(32, activation = 'sigmoid'),\n",
    "    tf.keras.layers.Dense(32, activation = 'softmax')\n",
    "])\n",
    "#we could have used ReLU but it will give positive values only. Or else we could use ReLU and then normalized it\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the model\n",
    "_ = model.fit(\n",
    "    x_train, y_train,\n",
    "    validation_data=(x_test, y_test),\n",
    "    epochs=20, batch_size=1024,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ml_server.py\n",
    "\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# import random\n",
    "\n",
    "from flask import Flask, request\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "model = tf.keras.models.load_model('model.h5')\n",
    "feature_model = tf.keras.models.Model(\n",
    "    model.inputs,\n",
    "    [layer.output for layer in model.layers]\n",
    ")\n",
    "\n",
    "_, (x_test, _) = tf.keras.datasets.mnist.load_data()\n",
    "x_test = x_test / 255.\n",
    "\n",
    "def get_prediction():\n",
    "    index = np.random.choice(x_test.shape[0])\n",
    "    image = x_test[index, :, :]\n",
    "    image_arr = np.reshape(image, (1,784))\n",
    "    return feature_model.predict(image_arr), image\n",
    "\n",
    "@app.route('/', methods=['GET','POST'])\n",
    "def index():\n",
    "    if request.method == 'POST':\n",
    "        preds, image = get_prediction()\n",
    "        final_preds = [p.tolist() for p in preds]\n",
    "        return json.dumps({\n",
    "            'prediction': final_preds,\n",
    "            'image': image.tolist()\n",
    "        })\n",
    "    return 'Welcome to my page! - Supriya Anand'\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile app.py\n",
    "\n",
    "import streamlit as st      #a package to run web app\n",
    "import json\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "URI = 'http://127.0.0.1:5000'\n",
    "\n",
    "st.title('Neural Network Web Visualizer')\n",
    "st.sidebar.markdown('##input image')\n",
    "\n",
    "if st.button('Get random prediction'): \n",
    "    response = requests.post(URI, data={})\n",
    "    response = json.loads(response, text)\n",
    "    preds = response.get('prediction')\n",
    "    image = response.get('image')\n",
    "    image = np.reshape(image, (28,28))\n",
    "    \n",
    "    st.sidebar.image(image, width=150)\n",
    "    \n",
    "    for layer, p in enumerate(preds):\n",
    "        numbers = np.squeeze(np.array(p))\n",
    "        plt.figure(figsize=(32,4))\n",
    "        \n",
    "        if layer == 2:\n",
    "            row = 1\n",
    "            col = 10\n",
    "        else:\n",
    "            row = 2\n",
    "            column = 16\n",
    "        \n",
    "        for i, number in em=numerate(numbers):\n",
    "            plt.subplot(row, col, i+1)\n",
    "            plt.imshow(number*np.ones(8,8,3).astype('float32'))\n",
    "            plt.xticks([])\n",
    "            plt.ytick([])\n",
    "            \n",
    "            if layer == 2:\n",
    "                plt.label(str(i), fontsize = 40)\n",
    "            \n",
    "            plt.subplots_adjust(wspace=0.05, hspace = 0.05)\n",
    "            plt.tight_layout()\n",
    "            st.text('Layer {}'.format(layer+1))\n",
    "            st.pyplot()\n",
    "        "
   ]
  }
 ]
}